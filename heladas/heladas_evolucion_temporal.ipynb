{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import xarray as xr\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np \n",
    "import time \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping, box\n",
    "import rioxarray\n",
    "import fsspec, re, aiohttp, requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130000.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130100.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130200.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130300.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130400.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130500.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130600.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130700.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130800.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310130900.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131000.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131100.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131200.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131300.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131400.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131500.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131600.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131700.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131800.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310131900.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310132000.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310132100.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310132200.nc',\n",
       " '/PRODUCTS/MSG/MLST/NETCDF/2023/10/13/NETCDF4_LSASAF_MSG_LST_MSG-Disk_202310132300.nc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_user=\"valensat\"\n",
    "server_passwd=\"ValensatMola\"\n",
    "\n",
    "product_name = 'MLST'\n",
    "variable_name = 'LST'\n",
    "year = '2023'\n",
    "month = '10'\n",
    "day = '13'\n",
    "\n",
    "fs = fsspec.filesystem('https',client_kwargs={'auth': aiohttp.BasicAuth(server_user, server_passwd)})\n",
    "\n",
    "url_path = f'https://datalsasaf.lsasvcs.ipma.pt/PRODUCTS/MSG/{product_name}/NETCDF/{year}/{month}/{day}/'\n",
    "r = requests.get(url_path, auth=(server_user, server_passwd))\n",
    "r1 = re.findall('/PRODUCTS/MSG/{}/NETCDF/{}/{}/{}/+\\w+\\w-+\\w+\\w+00.nc'.format(product_name, year, month, day), r.text)\n",
    "\n",
    "r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'202201010000'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_id = r1[0][-15:-3]\n",
    "product_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_name = 'MLST'\n",
    "variable_name = 'LST'\n",
    "year = '2022'\n",
    "month = '01'\n",
    "# day = '01'\n",
    "fs = fsspec.filesystem('https',client_kwargs={'auth': aiohttp.BasicAuth(server_user, server_passwd)})\n",
    "\n",
    "path_days = f'https://datalsasaf.lsasvcs.ipma.pt/PRODUCTS/MSG/{product_name}/NETCDF/{year}/{month}/'\n",
    "r_days = requests.get(path_days, auth=(server_user, server_passwd))\n",
    "r1_days = re.findall('/PRODUCTS/MSG/{}/NETCDF/{}/{}/+\\w+\\w'.format(product_name, year, month), r_days.text)\n",
    "\n",
    "for i in tqdm(range(0,  len(r1_days)), desc=\"Procesando archivos (mes)\"):\n",
    "    \n",
    "    day = str(r1_days[i][-2:])\n",
    "    url_path = f'https://datalsasaf.lsasvcs.ipma.pt/PRODUCTS/MSG/{product_name}/NETCDF/{year}/{month}/{day}/'\n",
    "    r = requests.get(url_path, auth=(server_user, server_passwd))\n",
    "    r1 = re.findall('/PRODUCTS/MSG/{}/NETCDF/{}/{}/{}/+\\w+\\w-+\\w+\\w+00.nc'.format(product_name, year, month, day), r.text)\n",
    "    mat_1dia = np.zeros((58,41,len(r1)))\n",
    "    tabla_dates = []\n",
    "    \n",
    "    for i in tqdm(range(0,  len(r1)), desc=\"Procesando archivos (dia)\"):\n",
    "\n",
    "        product_id = r1[i][-15:-3]\n",
    "        tabla_dates.append(str(product_id))\n",
    "\n",
    "        product = f\"https://{server_user}:{server_passwd}@thredds.lsasvcs.ipma.pt/thredds/dodsC/MSG/{product_name}/NETCDF/{year}/{month}/{day}/NETCDF4_LSASAF_MSG_LST_MSG-Disk_{product_id}.nc\"\n",
    "        ds = xr.open_dataset(product)\n",
    "        hora_img = ds.image_reference_time[11:-4]\n",
    "\n",
    "        cval = gpd.read_file('./data/delimitacion_cval/cval_provincias.shp')\n",
    "        ds.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "        ds_clip = ds[variable_name].squeeze().rio.clip(cval.geometry.apply(mapping), cval.crs)\n",
    "        # cval_reprojected = cval.to_crs(ds_clip.rio.crs)\n",
    "\n",
    "        # mat_heladas = np.where(ds_clip <= 2.3, 1, np.nan)\n",
    "        mat_1dia[:,:,i] = ds_clip\n",
    "\n",
    "        # np.save('./data/matrices_tablas/{}/{}/mat_1dia_{}.npy'.format(year, month, str(product_id)), mat_1dia)\n",
    "        # np.savetxt('./data/matrices_tablas/{}/{}/mat_1dia_info_{}.csv'.format(year, month, str(product_id)), tabla_dates, fmt='%s', delimiter=',')\n",
    "        pass\n",
    "    np.save('E:/Heladas/matrices_tablas/{}/{}/mat_1dia_{}.npy'.format(year, month, day), mat_1dia)\n",
    "    np.savetxt('E:/Heladas/matrices_tablas/{}/{}/mat_1dia_info_{}.csv'.format(year, month, day), tabla_dates, fmt='%s', delimiter=',')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:31<00:00, 18.82s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:49<00:00, 19.58s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:04<00:00, 20.20s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:38<00:00, 21.60s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [09:01<00:00, 22.57s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:20<00:00, 20.87s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:26<00:00, 21.09s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:06<00:00, 20.28s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:45<00:00, 19.38s/it]/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:47<00:00, 19.48s/it]/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:02<00:00, 20.09s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:04<00:00, 20.17s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:21<00:00, 18.41s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:30<00:00, 18.78s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:36<00:00, 19.01s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:20<00:00, 20.86s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [07:49<00:00, 20.43s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [08:30<00:00, 22.21s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:03<00:00, 20.16s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:54<00:00, 19.78s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [07:11<00:00, 18.75s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [07:22<00:00, 19.23s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:05<00:00, 17.72s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:17<00:00, 18.22s/it]it]  \n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:22<00:00, 18.44s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [08:02<00:00, 20.12s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:36<00:00, 19.02s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:58<00:00, 19.94s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:27<00:00, 18.63s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [07:04<00:00, 17.67s/it]it]\n",
      "Procesando archivos (mes): 100%|██████████| 30/30 [3:55:33<00:00, 471.12s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [05:39<00:00, 14.76s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [05:15<00:00, 13.74s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:22<00:00, 15.94s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:05<00:00, 15.24s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [05:46<00:00, 14.42s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [05:57<00:00, 15.54s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:13<00:00, 15.58s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:05<00:00, 15.21s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [05:41<00:00, 14.21s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:06<00:00, 15.28s/it]t]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:18<00:00, 15.76s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:01<00:00, 15.05s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:02<00:00, 15.10s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 22/22 [05:29<00:00, 14.97s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:07<00:00, 15.33s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:08<00:00, 15.34s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:16<00:00, 15.67s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:19<00:00, 15.82s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:10<00:00, 15.44s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [06:12<00:00, 16.17s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [05:47<00:00, 14.49s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:14<00:00, 15.59s/it]s/it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:06<00:00, 15.25s/it]it]  \n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:11<00:00, 15.49s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:11<00:00, 15.47s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 23/23 [05:43<00:00, 14.93s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [06:14<00:00, 15.60s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [05:39<00:00, 14.17s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [05:10<00:00, 12.95s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [05:37<00:00, 14.06s/it]it]\n",
      "Procesando archivos (dia): 100%|██████████| 24/24 [05:54<00:00, 14.76s/it]it]\n",
      "Procesando archivos (mes): 100%|██████████| 31/31 [3:05:34<00:00, 359.17s/it]\n"
     ]
    }
   ],
   "source": [
    "for year in ['2013', '2014']:\n",
    "    for month in ['01']:\n",
    "        product_name = 'MLST'\n",
    "        variable_name = 'LST'\n",
    "        fs = fsspec.filesystem('https',client_kwargs={'auth': aiohttp.BasicAuth(server_user, server_passwd)})\n",
    "\n",
    "        path_days = f'https://datalsasaf.lsasvcs.ipma.pt/PRODUCTS/MSG/{product_name}/NETCDF/{year}/{month}/'\n",
    "        r_days = requests.get(path_days, auth=(server_user, server_passwd))\n",
    "        r1_days = re.findall('/PRODUCTS/MSG/{}/NETCDF/{}/{}/+\\w+\\w'.format(product_name, year, month), r_days.text)\n",
    "\n",
    "        for i in tqdm(range(0,  len(r1_days)), desc=\"Procesando archivos (mes)\"):\n",
    "            \n",
    "            day = str(r1_days[i][-2:])\n",
    "            url_path = f'https://datalsasaf.lsasvcs.ipma.pt/PRODUCTS/MSG/{product_name}/NETCDF/{year}/{month}/{day}/'\n",
    "            r = requests.get(url_path, auth=(server_user, server_passwd))\n",
    "            r1 = re.findall('/PRODUCTS/MSG/{}/NETCDF/{}/{}/{}/+\\w+\\w-+\\w+\\w+00.nc'.format(product_name, year, month, day), r.text)\n",
    "            mat_1dia = np.zeros((58,41,len(r1)))\n",
    "            tabla_dates = []\n",
    "            \n",
    "            for i in tqdm(range(0,  len(r1)), desc=\"Procesando archivos (dia)\"):\n",
    "\n",
    "                product_id = r1[i][-15:-3]\n",
    "                tabla_dates.append(str(product_id))\n",
    "\n",
    "                product = f\"https://{server_user}:{server_passwd}@thredds.lsasvcs.ipma.pt/thredds/dodsC/MSG/{product_name}/NETCDF/{year}/{month}/{day}/NETCDF4_LSASAF_MSG_LST_MSG-Disk_{product_id}.nc\"\n",
    "                ds = xr.open_dataset(product)\n",
    "                hora_img = ds.image_reference_time[11:-4]\n",
    "\n",
    "                cval = gpd.read_file('./data/delimitacion_cval/cval_provincias.shp')\n",
    "                ds.rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "                ds_clip = ds[variable_name].squeeze().rio.clip(cval.geometry.apply(mapping), cval.crs)\n",
    "                # cval_reprojected = cval.to_crs(ds_clip.rio.crs)\n",
    "\n",
    "                # mat_heladas = np.where(ds_clip <= 2.3, 1, np.nan)\n",
    "                mat_1dia[:,:,i] = ds_clip\n",
    "\n",
    "                # np.save('./data/matrices_tablas/{}/{}/mat_1dia_{}.npy'.format(year, month, str(product_id)), mat_1dia)\n",
    "                # np.savetxt('./data/matrices_tablas/{}/{}/mat_1dia_info_{}.csv'.format(year, month, str(product_id)), tabla_dates, fmt='%s', delimiter=',')\n",
    "                pass\n",
    "            np.save('E:/Heladas/matrices_tablas/{}/{}/mat_1dia_{}.npy'.format(year, month, day), mat_1dia)\n",
    "            np.savetxt('E:/Heladas/matrices_tablas/{}/{}/mat_1dia_info_{}.csv'.format(year, month, day), tabla_dates, fmt='%s', delimiter=',')\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
